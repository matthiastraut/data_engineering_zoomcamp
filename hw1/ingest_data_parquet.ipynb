{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020ba842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import click\n",
    "import polars as pl\n",
    "from sqlalchemy import create_engine\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7d36be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@click.command()\n",
    "@click.option('--pg-user', default='postgres', help='PostgreSQL user')\n",
    "@click.option('--pg-pass', default='postgres', help='PostgreSQL password')\n",
    "@click.option('--pg-host', default='localhost', help='PostgreSQL host')\n",
    "@click.option('--pg-port', default=5432, type=int, help='PostgreSQL port')\n",
    "@click.option('--pg-db', default='ny_taxi', help='PostgreSQL database name')\n",
    "@click.option('--parquet-file', default='green_tripdata_2025-11.parquet', help='Parquet file to ingest')\n",
    "@click.option('--target-table', default='yellow_taxi_data', help='Target table name')\n",
    "@click.option('--chunksize', default=100000, type=int, help='Chunk size for reading parquet')\n",
    "def run(pg_user, pg_pass, pg_host, pg_port, pg_db, parquet_file, target_table, chunksize):\n",
    "    \"\"\"Ingest taxi data from parquet file into PostgreSQL database.\"\"\"\n",
    "    \n",
    "    engine = create_engine(f'postgresql://{pg_user}:{pg_pass}@{pg_host}:{pg_port}/{pg_db}')\n",
    "\n",
    "    # Read parquet file with Polars and scan for memory-efficient processing\n",
    "    df = pl.read_parquet(parquet_file)\n",
    "\n",
    "    # Convert to pandas for SQLAlchemy compatibility\n",
    "    pandas_df = df.to_pandas()\n",
    "    \n",
    "    # Write schema first (with empty dataframe)\n",
    "    pandas_df.head(0).to_sql(\n",
    "        name=target_table,\n",
    "        con=engine,\n",
    "        if_exists='replace'\n",
    "    )\n",
    "    \n",
    "    # Write data in chunks\n",
    "    total_rows = len(pandas_df)\n",
    "    num_chunks = (total_rows + chunksize - 1) // chunksize\n",
    "    \n",
    "    for i in tqdm(range(num_chunks), desc=f\"Writing to {target_table}\"):\n",
    "        start_idx = i * chunksize\n",
    "        end_idx = min((i + 1) * chunksize, total_rows)\n",
    "        chunk = pandas_df.iloc[start_idx:end_idx]\n",
    "        \n",
    "        chunk.to_sql(\n",
    "            name=target_table,\n",
    "            con=engine,\n",
    "            if_exists='append',\n",
    "            index=False\n",
    "        )\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-engineering-zoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
